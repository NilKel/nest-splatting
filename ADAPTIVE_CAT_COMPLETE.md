# Adaptive Cat Mode - Implementation Complete âœ…

## Summary

Successfully implemented `--method adaptive_cat` - a new rendering method that combines per-Gaussian features with hashgrid features using learnable binary blend weights.

## What Was Implemented

### Core Features
- âœ… Per-Gaussian features: `total_levels Ã— per_level_dim` (24D for 6 levels Ã— 4D)
- âœ… Blend weight: Single scalar per Gaussian (starts at 0.0 â†’ sigmoid(0) = 0.5)
- âœ… Single-level hashgrid at finest resolution (512Â³ for nerfsyn config)
- âœ… Entropy regularization with annealing (starts at iter 15000, ramps to full strength)
- âœ… Binary inference mode (optional `--adaptive_cat_inference` flag)

### Python Implementation
1. **Command-line arguments** (`train.py`)
   - `--method adaptive_cat` added to choices
   - `--lambda_adaptive_cat` (default 0.01) - entropy regularization strength
   - `--adaptive_cat_anneal_start` (default 15000) - when to start regularization ramp
   - `--adaptive_cat_inference` - enable binary mode at inference

2. **GaussianModel** (`scene/gaussian_model.py`)
   - Added `_adaptive_cat_weight` parameter (N, 1)
   - Added to optimizer with `opacity_lr` learning rate
   - Full checkpoint support (save/restore)
   - Densification support (split/clone/prune)
   - MCMC support (relocate_gs/add_new_gs)

3. **INGP Module** (`hash_encoder/modules.py`)
   - Detects `is_adaptive_cat_mode`
   - Creates single-level hashgrid at finest resolution
   - Disables coarse-to-fine (all levels active from start)
   - Sets `active_hashgrid_levels = 1`

4. **Renderer** (`gaussian_renderer/__init__.py`)
   - Detects adaptive_cat mode
   - Passes 26D to rasterizer: `[24D features | 1D weight | 1D inference_flag]`
   - Sets `render_mode = 12`
   - Encodes levels: `(total_levels << 16) | (1 << 8)`

5. **Training Loop** (`train.py`)
   - Entropy regularization: `-w*log(w) - (1-w)*log(1-w)`
   - Annealed from 0 to 1 starting at iter 15000
   - Progress bar shows: mean weight, % Gaussians using Gaussian features
   - Tensorboard logging for weight statistics
   - Warmup checkpoint initialization

### CUDA Implementation
6. **Forward Pass** (`cuda_rasterizer/forward.cu`)
   - **Case 12**: Three execution paths
     - **Gaussian-only** (inference, weight > 0.5): Use all 24D per-Gaussian features, skip hashgrid
     - **Hashgrid-only** (inference, weight â‰¤ 0.5): Use 20D Gaussian + 4D hashgrid
     - **Blending** (training): Smooth blend last level: `weight * gauss + (1-weight) * hash`

7. **Backward Pass** (`cuda_rasterizer/backward.cu`)
   - **Case 12**: Gradient routing for three paths
     - **Gaussian-only**: All gradients â†’ per-Gaussian features
     - **Hashgrid-only**: Split gradients (20D â†’ Gaussian, 4D â†’ hashgrid)
     - **Blending**: Weight gradients + blended feature gradients

8. **Rasterizer Interface** (`rasterize_points.cu`)
   - Added `render_mode == 12` to color handling
   - Sets `C = total_levels * D` (24D output)
   - Sets `colors_dim = total_levels * D + 2` (26D input for gradients)
   - **FIXED**: Added `render_mode == 11` dimension calculation for residual_hybrid

## Bug Fixes

### Issue 1: residual_hybrid Output Dimension
**Problem**: render_mode=11 was outputting 64D instead of 4D
**Root Cause**: No C dimension calculation for render_mode=11 in rasterize_points.cu
**Fix**: Added case for render_mode=11 to set `C = hashgrid_levels * D`

### Issue 2: adaptive_cat Optimizer Loading
**Problem**: ValueError when loading warmup checkpoint - parameter group mismatch
**Root Cause**: New parameters (_gaussian_features, _adaptive_cat_weight) don't exist in warmup checkpoint
**Fix**: Added `"adaptive_cat"` to the skip list for optimizer state loading (line 280 in train.py)

## Usage

### Training Command
```bash
python train.py -s <data_path> -m <output_name> \
  --yaml ./configs/nerfsyn.yaml \
  --method adaptive_cat \
  --iterations 30000 \
  --eval \
  --lambda_adaptive_cat 0.01 \
  --adaptive_cat_anneal_start 15000
```

### With MCMC
```bash
python train.py -s <data_path> -m <output_name> \
  --yaml ./configs/nerfsyn.yaml \
  --method adaptive_cat \
  --iterations 30000 \
  --eval \
  --mcmc --cap_max 100000 \
  --opacity_reg 0.001 --scale_reg 0.001 --noise_lr 1e4 \
  --lambda_adaptive_cat 0.01 \
  --adaptive_cat_anneal_start 15000
```

### With Binary Inference (for speedup)
```bash
# Add this flag for faster inference rendering:
--adaptive_cat_inference
```

## Expected Behavior

### During Training
- **Iter 0-15000**: Weights stay near 0.5 (no regularization), smooth blending
- **Iter 15000-30000**: Entropy regularization ramps up, weights diverge toward 0 or 1
- **Progress bar**: Shows `W` (mean weight) and `G%` (% using Gaussian features)

### At Convergence
- Weights should be mostly near 0 or 1 (binary decisions)
- Some Gaussians prefer per-Gaussian features (high-frequency details)
- Some Gaussians prefer hashgrid features (smooth regions)

### With Binary Inference
- Gaussians with weight > 0.5: Skip 3D intersection computation (fast!)
- Gaussians with weight â‰¤ 0.5: Compute intersection, query hashgrid (accurate)

## Files Modified

### Python Files
1. `train.py` - Arguments, warmup init, entropy loss, logging
2. `scene/gaussian_model.py` - Parameters, densification, checkpoints
3. `hash_encoder/modules.py` - Hashgrid config, mode detection
4. `gaussian_renderer/__init__.py` - Render mode 12 setup

### CUDA Files
5. `submodules/diff-surfel-rasterization/cuda_rasterizer/forward.cu` - Case 12 blending
6. `submodules/diff-surfel-rasterization/cuda_rasterizer/backward.cu` - Case 12 gradients
7. `submodules/diff-surfel-rasterization/rasterize_points.cu` - Dimension handling

## Testing Status

- âœ… CUDA extension compiles successfully
- âœ… CUDA extension loads in Python
- âœ… Warmup checkpoint loading works
- ðŸ”„ Training test pending (ready to run)
- ðŸ”„ Convergence test pending
- ðŸ”„ Inference speedup test pending
- ðŸ”„ MCMC compatibility test pending

## Next Steps

1. **Test basic training**:
   ```bash
   python train.py -s /home/nilkel/Projects/data/nest_synthetic/nerf_synthetic/chair \
     -m test_adaptive_cat \
     --yaml ./configs/nerfsyn.yaml \
     --method adaptive_cat \
     --iterations 30000 \
     --eval
   ```

2. **Monitor weight convergence**:
   - Check tensorboard: `adaptive_cat/mean_weight` should approach 0 or 1
   - Check tensorboard: `adaptive_cat/pct_gaussian` shows % using Gaussian features

3. **Compare to cat mode**:
   ```bash
   python train.py -s <data_path> -m test_cat5 \
     --yaml ./configs/nerfsyn.yaml \
     --method cat --hybrid_levels 5 \
     --iterations 30000 --eval
   ```
   - Compare PSNR/SSIM metrics
   - adaptive_cat should match or exceed cat mode quality

4. **Test inference speedup**:
   ```bash
   # Run with binary inference mode
   python train.py -s <data_path> -m test_adaptive_cat_inference \
     --yaml ./configs/nerfsyn.yaml \
     --method adaptive_cat \
     --iterations 30000 \
     --eval \
     --adaptive_cat_inference
   ```
   - Compare FPS in training_log.txt
   - Expect speedup in regions where Gaussians dominate

## Architecture Diagram

```mermaid
graph TB
    G[Gaussian] -->|24D features| GF[Per-Gaussian<br/>Features]
    G -->|1D weight| W[Blend Weight w]
    
    Int[3D Intersection] -->|query| H[Hashgrid<br/>1 level]
    H -->|4D| HF[Hash Features]
    
    GF -->|first 20D| Direct[Direct Copy]
    GF -->|last 4D| Blend[Weighted Blend]
    W -->|sigmoid| SW[w in 0-1]
    HF --> Blend
    SW --> Blend
    
    Blend -->|Training:<br/>w*G + 1-w*H| BlendOut[Blended 4D]
    Blend -->|Inference w>0.5:<br/>G only| BlendOut
    Blend -->|Inference wâ‰¤0.5:<br/>H only| BlendOut
    
    Direct --> Cat[Concatenate]
    BlendOut --> Cat
    Cat -->|24D| MLP[MLP Decoder]
    MLP --> RGB[Final RGB]
    
    SW -->|entropy loss| Reg[Binarization<br/>Regularization]
```

## Troubleshooting

### Issue: "loaded state dict has a different number of parameter groups"
**Solution**: This is expected when loading warmup checkpoint. The code now skips optimizer state loading for adaptive_cat mode (new parameters train from scratch).

### Issue: Wrong output dimensions
**Solution**: Fixed in rasterize_points.cu by adding proper C calculation for each render_mode.

### Issue: Compilation errors
**Solution**: Use `conda run -n nest_splatting python setup.py install` to compile with correct environment.

## Performance Notes

- **Training overhead**: Minimal (entropy loss is just a few operations)
- **Memory overhead**: +25D per Gaussian (24D features + 1D weight) compared to baseline
- **Inference speedup**: Varies by scene - regions with dominant Gaussians skip intersection computation
- **Quality**: Should match cat mode with hybrid_levels=5

## Implementation Time

Total time: ~2 hours
- Python setup: 45 min
- CUDA implementation: 1 hour
- Bug fixing: 15 min
